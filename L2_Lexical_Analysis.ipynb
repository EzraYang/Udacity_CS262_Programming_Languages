{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 2\n",
    "\n",
    "Specify HTML and JavaScript words\n",
    "\n",
    "* process in high-level\n",
    "    * ![](http://note.youdao.com/yws/public/resource/1c03bd415f0f751e46aa6d97ed5acbcb/xmlnote/WEBRESOURCE9ba80c2540e4fddfb82d7172e267c2cb/27846)\n",
    "\n",
    "* Token: smallest unit of lexical analysis\n",
    "    * ![](http://note.youdao.com/yws/public/resource/1c03bd415f0f751e46aa6d97ed5acbcb/xmlnote/WEBRESOURCE9a4a8ce0807860077f3c68cde5e5bec0/27887)\n",
    "    * ![](http://note.youdao.com/yws/public/resource/1c03bd415f0f751e46aa6d97ed5acbcb/xmlnote/WEBRESOURCE39414946d624cd075866978090e29944/27849)\n",
    "    * ![](http://note.youdao.com/yws/public/resource/1c03bd415f0f751e46aa6d97ed5acbcb/xmlnote/WEBRESOURCEdbce19292f9254766c9d6f15fd23228a/27850)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# defining token in html\n",
    "\n",
    "\n",
    "![](http://note.youdao.com/yws/public/resource/1c03bd415f0f751e46aa6d97ed5acbcb/xmlnote/WEBRESOURCEf6ef3c807596f1bbe4190c8317e06382/27891)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def t_NUM_decimal(token):\n",
    "  r'[0-9]+'\n",
    "  token.value = int(token.value) # you can modify the return value of a token\n",
    "  token.type = 'NUM'\n",
    "  return token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On dealing with Quated Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Quoted Strings\n",
    "\n",
    "# Suppose a string starts with \" and ends with \" and contains any number of\n",
    "# characters except \". Write a definition for t_STRING.\n",
    "\n",
    "# Match Exactly:\n",
    "#     \"cuneiform\"\n",
    "#     \"sumerian writing\"\n",
    "# Do Not Match Exactly:\n",
    "#     \"esc \\\" ape\"\n",
    "#     League of Nations Treaty Series \n",
    "\n",
    "def t_STRING(token):\n",
    "    r'\"[^\"]*\"'\n",
    "    token.value = token.value[1:-1] # strip off the double quotes\n",
    "    return token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def t_WHITESPACE(token):\n",
    "    r' '\n",
    "    pass  # don't return anything"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Whitespace\n",
    "\n",
    "# Suppose a WORD is any number of characters EXCEPT < > or space. \n",
    "# A WORD token should leave its value unchanged.\n",
    "\n",
    "# Submit a definition for t_WORD.\n",
    "\n",
    "def t_WORD(token):\n",
    "    r'[^ <>]+'\n",
    "    return token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# defining tokens in javascript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### identifier\n",
    "\n",
    "identifier is a formal way of saying variable name and function name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Identifier\n",
    "\n",
    "# Identifiers are textual string descriptions that refer to program elements,\n",
    "# such as variables and functions. Write a indentifier token rule for Javascript identifiers.\n",
    "\n",
    "# The token rule should match:\n",
    "\n",
    "#   factorial\n",
    "#   underscore_separated\n",
    "#   mystery\n",
    "#   ABC\n",
    "\n",
    "# The token rule should not match:\n",
    "\n",
    "#   _starts_wrong\n",
    "#   123\n",
    "\n",
    "\n",
    "def t_IDENTIFIER(token):\n",
    "    r'[a-zA-Z]+(?:_(?:[a-zA-Z]+)+)*'\n",
    "    return token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Numbers\n",
    "\n",
    "# Write a indentifier token rule for Javascript numbers that converts the value\n",
    "# of the token to a float.\n",
    "\n",
    "# The token rule should match:\n",
    "\n",
    "#    12\n",
    "#    5.6\n",
    "#    -1.\n",
    "#    3.14159\n",
    "#    -8.1\n",
    "#    867.5309\n",
    "\n",
    "# The token rule should not match:\n",
    "\n",
    "#    1.2.3.4\n",
    "#    five\n",
    "#    jenny\n",
    "\n",
    "def t_NUMBER(token):\n",
    "    # escape the . cause it has other meaning in regular expression\n",
    "    r'-?[0-9]+(?:\\.?[0-9]*)?'\n",
    "    token.value = float(token.value)\n",
    "    return token\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the comment at end of the line in javascript\n",
    "def t_eolcomment(token):\n",
    "    # start with // followed by any char other than new line\n",
    "    r'//[^\\n]*'\n",
    "    pass  # throw them away"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lexical Analyzer (lexer)\n",
    "\n",
    "a collection of token definitions\n",
    "\n",
    "rule of order: first comer wins!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# an example lexer to parse html\n",
    "# this will throw error in jupyter notebook, \n",
    "# copy the code in a standard python IDE then you will see it run\n",
    "\n",
    "import ply.lex as lex\n",
    "\n",
    "tokens = (\n",
    "    'LANGLE',  # <\n",
    "    'LANGLESLASH',  # </\n",
    "    'RANGLE',  # >\n",
    "    'EQUAL',  # = \n",
    "    'STRING',  # \"hello\"\n",
    "    'WORD',  # Welcome!\n",
    ") \n",
    "states = (\n",
    "    ('htmlcomment', 'exclusive'),\n",
    ")\n",
    "\n",
    "t_ignore = ' ' # shortcut for whitespace token\n",
    "\n",
    "def t_htmlcomment(token):\n",
    "    r'<!--'\n",
    "    token.lexer.begin('htmlcomment')\n",
    "    \n",
    "# jump back to the state before you enter htmlcomment state\n",
    "def t_htmlcomment_end(token):\n",
    "    r'-->'\n",
    "    token.lexer.lineno += token.value.count('\\n')\n",
    "    token.lexer.begin('INITIAL') \n",
    "    \n",
    "# within the htmlcomment state,\n",
    "# anything that's not matching the starting and ending regexp\n",
    "# will be regnized as an error and just be skipped\n",
    "def t_htmlcomment_error(token):\n",
    "    token.lexer.skip(1)\n",
    "\n",
    "def t_newline(token):\n",
    "    r'\\n'\n",
    "    token.lexer.lineno += 1\n",
    "    pass\n",
    "\n",
    "def t_LANGLESLASH(token):  # 优先于LANGLE\n",
    "    r'</'\n",
    "    return token\n",
    "\n",
    "def t_LANGLE(token):\n",
    "    r'<'\n",
    "    return token\n",
    "\n",
    "def t_RANGLE(token):\n",
    "    r'>'\n",
    "    return token\n",
    "\n",
    "def t_EQUAL(token):\n",
    "    r'='\n",
    "    return token\n",
    "\n",
    "def t_STRING(token):\n",
    "    r'\"[^\"]*\"'\n",
    "    token.value = token.value[1:-1] # strip off the double quotes\n",
    "    return token\n",
    "\n",
    "def t_WORD(token):\n",
    "    r'[^ <>]+'\n",
    "    return token\n",
    "\n",
    "webpage = \"This is <b>my</b> webpage!\"\n",
    "# tell the lex library to init a lexer using definitions above\n",
    "lexer = lex.lex()  \n",
    "\n",
    "# tell the lexer which string to break up\n",
    "# output will be a list of tokens\n",
    "lexer.input(webpage)  \n",
    "while True:\n",
    "    tok = lexer.token() # returns the next token that's available\n",
    "    if not tok:\n",
    "        break\n",
    "    print(tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# an example of html and javascript\n",
    "\n",
    "<p>\n",
    "    Welcome to <b>Steven</b>'s webpage.\n",
    "    This is a link <A href=\"heep://www.google.com\">to google</a>.\n",
    "    Five factorial (aka <i>5!</i>) is :\n",
    "    <script type=\"text/javascript\">\n",
    "        # same as def in python\n",
    "        function factorial(n) {\n",
    "            if ( n == 0){\n",
    "                return 1;\n",
    "            }\n",
    "            return n * factoiral(n-1);\n",
    "        }\n",
    "        # same as print in python\n",
    "        document.write(factorial(5));\n",
    "    </script>\n",
    "<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Lesson 2 \n",
    "\n",
    "# wrap up\n",
    "\n",
    "* breaking html and javascript into the smallest unit\n",
    "\n",
    "# next\n",
    "\n",
    "* combine those tokens into sentences that make sense\n",
    "* using the rules of syntax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# some of pset2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kingsolver\n"
     ]
    }
   ],
   "source": [
    "# Bonus Practice: Find Max\n",
    "\n",
    "# This assignment is not graded and we encourage you to experiment. Learning is\n",
    "# fun!\n",
    "\n",
    "# Given a list l and a function f, return the element of l that maximizes f.\n",
    "\n",
    "# Assume:\n",
    "#    l is not empty\n",
    "#    f returns a number\n",
    "\n",
    "# Example:\n",
    "\n",
    "l = ['Barbara', 'kingsolver', 'wrote', 'The', 'Poisonwood','Bible']\n",
    "f = len\n",
    "\n",
    "# official solution\n",
    "\n",
    "def findmax(f, l):\n",
    "    best_element_sofar = None\n",
    "    best_f_value_sofar = None\n",
    "    for ele in l:\n",
    "        f_value = f(ele)\n",
    "        # print(\"f_value is %s, ele is %s\" %(f_value,ele))\n",
    "        if best_f_value_sofar == None or f_value > best_f_value_sofar:\n",
    "            best_element_sofar = ele\n",
    "            best_f_value_sofar = f_value\n",
    "    return best_element_sofar\n",
    "   \n",
    "# print(findmax( lambda(word):word.find(\"l\"), l))\n",
    "\"\"\"\n",
    "l = ['Barbara', 'kingsolver', 'wrote', 'The', 'Poisonwood','Bible']\n",
    "f = len\n",
    "print(findmax(f, l))\n",
    "\n",
    "l = [18, -6, 99, -9]\n",
    "f = abs\n",
    "print(findmax(f, l))\n",
    "\"\"\"\n",
    "def lpos(word):\n",
    "    return word.find(\"l\")\n",
    "l = ['Barbara', 'kingsolver', 'wrote', 'The', 'Poisonwood','Bible']\n",
    "f = lpos\n",
    "print(findmax(f, l))\n",
    "\n",
    "l = ['Barbara', 'kingsolver', 'wrote', 'The', 'Poisonwood','Bible']\n",
    "# anonymous function defining\n",
    "print(findmax( lambda word :word.find(\"l\"), l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hexadecimal numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hexadecimal Numbers\n",
    "# \n",
    "# In this exercise you will write a lexical analyzer that breaks strings up\n",
    "# into whitespace-separated identifiers and numbers. An identifier is a\n",
    "# sequence of one or more upper- or lower-case letters. In this exercise,\n",
    "# however, there are two types of numbers: decimal numbers, and\n",
    "# _hexadecimal_ numbers. \n",
    "#\n",
    "# Humans usually write numbers using \"decimal\" or \"base 10\" notation. The \n",
    "# number# 234 means 2*10^2 + 3*10 + 4*1. \n",
    "#\n",
    "# It is also possible to write numbers using other \"bases\", like \"base 16\"\n",
    "# or \"hexadecimal\". Computers often use base 16 because 16 is a convenient\n",
    "# power of two (i.e., it is a closer fit to the \"binary\" system that\n",
    "# computers use internally). A hexadecimal number always starts with the\n",
    "# two-character prefix \"0x\" so that you know not to mistake it for a binary\n",
    "# number. The number 0x234 means\n",
    "#       2 * 16^2\n",
    "#     + 3 * 16^1\n",
    "#     + 4 * 16^0 \n",
    "# = 564 decimal. \n",
    "#\n",
    "# Because base 16 is larger than base 10, the letters 'a' through 'f' are\n",
    "# used to represent the numbers '10' through '15'. So the hexadecimal\n",
    "# number 0xb is the same as the decimal number 11. When read out loud, the\n",
    "# \"0x\" is often pronounced like \"hex\". \"0x\" must always be followed by at\n",
    "# least one hexadecimal digit to count as a hexadecimal number. \n",
    "# \n",
    "# Modern programming languages like Python can understand hexadecimal\n",
    "# numbers natively! Try it: \n",
    "#\n",
    "# print 0x234  # uncomment me to see 564 printed\n",
    "# print 0xb    # uncomment me to see 11 printed \n",
    "#\n",
    "# This provides an easy way to test your knowledge of hexadecimal. \n",
    "#\n",
    "# For this assignment you must write token definition rules (e.g., t_ID,\n",
    "# t_NUM_hex) that will break up a string of whitespace-separated\n",
    "# identifiers and numbers (either decimal or hexadecimal) into ID and NUM\n",
    "# tokens. If the token is an ID, you should store its text in the\n",
    "# token.value field. If the token is a NUM, you must store its numerical\n",
    "# value (NOT a string) in the token.value field. This means that if a\n",
    "# hexadecimal string is found, you must convert it to a decimal value. \n",
    "#\n",
    "# Hint 1: When presented with a hexadecimal string like \"0x2b4\", you can\n",
    "# convert it to a decimal number in stages, reading it from left to right:\n",
    "#       number = 0              # '0x' \n",
    "#       number = number * 16 \n",
    "#       number = number + 2     # '2'\n",
    "#       number = number * 16 \n",
    "#       number = number + 11    # 'b'\n",
    "#       number = number * 16\n",
    "#       number = number + 4     # '4'\n",
    "# Of course, since you don't know the number of digits in advance, you'll \n",
    "# probably want some sort of loop. There are other ways to convert a\n",
    "# hexadecimal string to a number. You may use any way that works. \n",
    "#\n",
    "# Hint 2: The Python function ord() will convert a single letter into \n",
    "# an ordered internal numerical representation. This allows you to perform\n",
    "# simple arithmetic on numbers:  \n",
    "# \n",
    "# print ord('c') - ord('a') == 2 \n",
    "\n",
    "import ply.lex as lex\n",
    "\n",
    "tokens = ('NUM', 'ID')\n",
    "\n",
    "####\n",
    "# Fill in your code here.\n",
    "####\n",
    "def t_NUM_hex(token):\n",
    "    r'0x(?:[0-9]|[a-f])+'\n",
    "    # then convert the hex number into decimal\n",
    "    letter = token.value[2]\n",
    "    # if 0x0, the hex number is 0    \n",
    "    if letter == '0':\n",
    "        token.value = 0\n",
    "    # hex number is other than 0\n",
    "    else:\n",
    "        numString = token.value[2:]\n",
    "        num = 0\n",
    "        mapping = {\n",
    "            'a':10, \n",
    "            'b':11,\n",
    "            'c':12,\n",
    "            'd':13,\n",
    "            'e':14,\n",
    "            'f':15}\n",
    "        for i in range(0, len(numString)):\n",
    "            # if it's 0-9\n",
    "            if ord(numString[i]) < 58:\n",
    "                num += int(numString[i])\n",
    "                num *= 16\n",
    "            # if it's a-f\n",
    "            else:\n",
    "                num += mapping[numString[i]]\n",
    "                num *= 16\n",
    "        num = num / 16\n",
    "        token.value = num\n",
    "    token.type = 'NUM'\n",
    "    return token\n",
    "\n",
    "\n",
    "def t_NUM_decimal(token):\n",
    "  r'[0-9]+'\n",
    "  token.value = int(token.value) # won't work on hex numbers!\n",
    "  token.type = 'NUM'\n",
    "  return token\n",
    "  \n",
    "def t_ID(token):\n",
    "    r'(?:[a-z]|[A-Z])+'\n",
    "    token.type = 'ID'\n",
    "    return token\n",
    "\n",
    "t_ignore = ' \\t\\v\\r'\n",
    "\n",
    "def t_error(t):\n",
    "  print \"Lexer: unexpected character \" + t.value[0]\n",
    "  t.lexer.skip(1) \n",
    "\n",
    "# We have included some testing code to help you check your work. You will\n",
    "# probably want to add your own additional tests. \n",
    "lexer = lex.lex() \n",
    "\n",
    "def test_lexer(input_string):\n",
    "  lexer.input(input_string)\n",
    "  result = [ ] \n",
    "  while True:\n",
    "    tok = lexer.token()\n",
    "    if not tok: break\n",
    "    result = result + [(tok.type, tok.value)]\n",
    "  return result\n",
    "\n",
    "question1 = \"0x19 equals 25\" # 0x19 = (1*16) + 9\n",
    "answer1 = [('NUM', 25), ('ID', 'equals'), ('NUM', 25) ]\n",
    "\n",
    "print test_lexer(question1) == answer1\n",
    "\n",
    "question2 = \"0xfeed MY 0xface\" \n",
    "answer2 = [('NUM', 65261), ('ID', 'MY'), ('NUM', 64206) ]\n",
    "\n",
    "print test_lexer(question2) == answer2\n",
    "\n",
    "\n",
    "question3 = \"tricky 0x0x0x\" \n",
    "answer3 = [('ID', 'tricky'), ('NUM', 0), ('ID', 'x'), ('NUM', 0), ('ID', 'x')]\n",
    "\n",
    "print test_lexer(question3) == answer3\n",
    "\n",
    "\n",
    "question4 = \"in 0xdeed\"\n",
    "print test_lexer(question4)\n",
    "\n",
    "question5 = \"where is the 0xbeef\"\n",
    "print test_lexer(question5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### email addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Email Addresses & Spam\n",
    "#\n",
    "# In this assignment you will write Python code to to extract email\n",
    "# addresses from a string of text. To avoid unsolicited commercial email\n",
    "# (commonly known as \"spam\"), users sometimes add the text NOSPAM to an\n",
    "# other-wise legal email address, trusting that humans will be smart enough\n",
    "# to remove it but that machines will not. As we shall see, this provides\n",
    "# only relatively weak protection. \n",
    "#\n",
    "# For the purposes of this exercise, an email address consists of a\n",
    "# word, an '@', and a domain name. A word is a non-empty sequence\n",
    "# of upper- or lower-case letters. A domain name is a sequence of two or\n",
    "# more words, separated by periods. \n",
    "#\n",
    "# Example: wes@udacity.com\n",
    "# Example: username@domain.name\n",
    "# Example: me@this.is.a.very.long.domain.name\n",
    "#\n",
    "# If an email address has the text NOSPAM (uppercase only) anywhere in it,\n",
    "# you should remove all such text. Example: \n",
    "# 'wes@NOSPAMudacity.com' -> 'wes@udacity.com' \n",
    "# 'wesNOSPAM@udacity.com' -> 'wes@udacity.com' \n",
    "#\n",
    "# You should write a procedure addresses() that accepts as input a string.\n",
    "# Your procedure should return a list of valid email addresses found within\n",
    "# that string -- each of which should have NOSPAM removed, if applicable. \n",
    "#\n",
    "# Hint 1: Just as we can FIND a regular expression in a string using\n",
    "# re.findall(), we can also REPLACE or SUBSTITUTE a regular expression in a\n",
    "# string using re.sub(regexp, new_text, haystack). Example: \n",
    "# \n",
    "# print re.sub(r\"[0-9]+\", \"NUMBER\", \"22 + 33 = 55\") \n",
    "# \"NUMBER + NUMBER = NUMBER\" \n",
    "#\n",
    "# Hint 2: Don't forget to escape special characters. \n",
    "#\n",
    "# Hint 3: You don't have to write very much code to complete this exercise:\n",
    "# you just have to put together a few concepts. It is possible to complete\n",
    "# this exercise without using a lexer at all. You may use any approach that\n",
    "# works. \n",
    "\n",
    "\n",
    "import ply.lex as lex\n",
    "import re \n",
    "\n",
    "# Fill in your answer here. \n",
    "\n",
    "def addresses(haystack): \n",
    "  # ...\n",
    "  nospamRemoved = re.sub(r'NOSPAM', '', haystack)\n",
    "  emailRegexp = r'[A-Za-z]+@[A-Za-z]+(?:\\.[A-Za-z]+)+'\n",
    "  pureEmail = re.findall(emailRegexp, nospamRemoved)\n",
    "  return pureEmail\n",
    "\n",
    "\n",
    "# We have provided a single test case for you. You will probably want to\n",
    "# write your own. \n",
    "input1 = \"\"\"louiseNOSPAMaston@germany.de (1814-1871) was an advocate for\n",
    "democracy. irmgardNOSPAMkeun@NOSPAMweimar.NOSPAMde (1905-1982) wrote about\n",
    "the early nazi era. rahelNOSPAMvarnhagen@berlin.de was honored with a 1994\n",
    "deutsche bundespost stamp. seti@home is not actually an email address.\"\"\"\n",
    "\n",
    "output1 = ['louiseaston@germany.de', 'irmgardkeun@weimar.de', 'rahelvarnhagen@berlin.de']\n",
    "\n",
    "print addresses(input1) == output1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### javascript numbers and identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# JavaScript: Numbers & Strings\n",
    "# \n",
    "# In this exercise you will finish out the token definitions for JavaScript \n",
    "# by handling Numbers, Identifiers and Strings. \n",
    "#\n",
    "# We have split the lexing of JavaScript into two exercises so that\n",
    "# you have a chance to demonstrate your mastery of the concepts\n",
    "# independently (i.e., so that you can get one of them right even if the\n",
    "# other proves difficult). We could easily make a full JavaScript lexer by\n",
    "# putting all of the rules together. \n",
    "#\n",
    "# For this assignment, a JavaScript IDENTIFIER must start with an upper- or\n",
    "# lower-case character. It can then contain any number of upper- or\n",
    "# lower-case characters or underscores. Its token.value is the textual\n",
    "# string of the identifier. \n",
    "#       Yes:    my_age\n",
    "#       Yes:    cRaZy\n",
    "#       No:     _starts_with_underscore\n",
    "#\n",
    "# For this assignment, a JavaScript NUMBER is one or more digits. A NUMBER\n",
    "# can start with an optional negative sign. A NUMBER can contain a decimal\n",
    "# point, which can then be followed by zero or more additional digits. Do\n",
    "# not worry about hexadecimal (only base 10 is allowed in this problem).\n",
    "# The token.value of a NUMBER is its floating point value (NOT a string).\n",
    "#       Yes:    123\n",
    "#       Yes:    -456\n",
    "#       Yes:    78.9\n",
    "#       Yes:    10.\n",
    "#       No:     +5\n",
    "#       No:     1.2.3\n",
    "#\n",
    "# For this assignment, a JavaScript STRING is zero or more characters\n",
    "# contained in double quotes. A STRING may contain escaped characters.\n",
    "# Notably, \\\" does not end a string. The token.value of a STRING is\n",
    "# its contents (not including the outer double quotes). \n",
    "#       Yes:    \"hello world\"\n",
    "#       Yes:    \"this has \\\"escaped quotes\\\"\"\n",
    "#       No:     \"no\"t one string\" \n",
    "#\n",
    "# Hint: float(\"2.3\") = 2.3\n",
    "\n",
    "import ply.lex as lex\n",
    "\n",
    "tokens = (\n",
    "        'IDENTIFIER',   \n",
    "        'NUMBER',       \n",
    "        'STRING',       \n",
    ")\n",
    "\n",
    "#\n",
    "# Write your code here. \n",
    "#\n",
    "\n",
    "def t_IDENTIFIER(t):\n",
    "    r'[a-zA-Z](?:[a-zA-Z]|_)*'\n",
    "    return t\n",
    "    \n",
    "def t_NUMBER(t):\n",
    "    r'-?[0-9]+(?:\\.[0-9]*)?'\n",
    "    t.value = float(t.value)\n",
    "    return t\n",
    "    \n",
    "def t_STRING(t):\n",
    "    r'\"(?:[^\\\\]|[\\\\.*])*\"'\n",
    "    t.value = t.value[1:-1]\n",
    "    return t\n",
    "    \n",
    "\n",
    "\n",
    "t_ignore                = ' \\t\\v\\r' # whitespace \n",
    "\n",
    "def t_newline(t):\n",
    "        r'\\n'\n",
    "        t.lexer.lineno += 1\n",
    "\n",
    "def t_error(t):\n",
    "        print \"JavaScript Lexer: Illegal character \" + t.value[0]\n",
    "        t.lexer.skip(1)\n",
    "\n",
    "# We have included two test cases to help you debug your lexer. You will\n",
    "# probably want to write some of your own. \n",
    "\n",
    "lexer = lex.lex() \n",
    "\n",
    "def test_lexer(input_string):\n",
    "  lexer.input(input_string)\n",
    "  result = [ ] \n",
    "  while True:\n",
    "    tok = lexer.token()\n",
    "    if not tok: break\n",
    "    result = result + [tok.type,tok.value]\n",
    "  return result\n",
    "\n",
    "input1 = 'some_identifier -12.34 \"a \\\\\"escape\\\\\" b\"'\n",
    "output1 = ['IDENTIFIER', 'some_identifier', 'NUMBER', -12.34, 'STRING', \n",
    "'a \\\\\"escape\\\\\" b']\n",
    "print test_lexer(input1) == output1\n",
    "\n",
    "\n",
    "input2 = '-12x34' \n",
    "output2 = ['NUMBER', -12.0, 'IDENTIFIER', 'x', 'NUMBER', 34.0]\n",
    "print test_lexer(input2) == output2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Euclid's Algorithm in javascript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Euclid's Algorithm\n",
    "#\n",
    "# Format: Submit JavaScript Code\n",
    "#\n",
    "# In mathematics, because 8 divides 24 evenly, we say that 8 is a\n",
    "# *divisor* of 24. When computing, it is often useful to find the\n",
    "# largest divisor that two numbers have in common. For example, 36\n",
    "# and 24 are both divisible by 2, 3, 4, and 12: the greatest\n",
    "# divisor that they have in common is 12. It turns out that finding\n",
    "# common divisors for numbers is critical for modern cryptography,\n",
    "# including public-key crypto systems such as RSA: a backbone of internet\n",
    "# commerce. \n",
    "#\n",
    "# Perhaps the oldest algorithm known -- ever! -- is for computing the\n",
    "# greatest common divisor of two positive numbers. It is attributed to the\n",
    "# Greek mathematician Euclid around 300 BCE. Here's how it goes: \n",
    "#\n",
    "# You are computing the greatest common divisor (\"gcd\") of two positive\n",
    "# integers called \"a\" and \"b\". The gcd can be computed recursively (or\n",
    "# iteratively) using the following three rules: \n",
    "#\n",
    "#       gcd(a,b) = a                    if a == b\n",
    "#       gcd(a,b) = gcd(a-b,b)           if a > b\n",
    "#       gcd(a,b) = gcd(a,b-a)           if a < b \n",
    "#\n",
    "# Write a JavaScript (_not_ Python) program that declares a function called gcd\n",
    "# that accepts two positive integer arguments a and b and returns their greatest\n",
    "# common divisor. Store your function in a variable called javascriptcode.\n",
    "#\n",
    "# We will return anything printed out when you hit submit as we execute the\n",
    "# JavaScript behind the scenes.\n",
    "\n",
    "javascriptcode=\"\"\"\n",
    "function gcd(a,b) {\n",
    "    //Write Code Here\n",
    "    if ( a == b ) {\n",
    "        return a;\n",
    "    } else if (a > b){\n",
    "        return gcd(a-b, b);\n",
    "    } else {\n",
    "        return gcd(a, b-a);\n",
    "    }\n",
    "}\n",
    "\n",
    "write( gcd(24,8) == 8 ); \n",
    "write(\" \");\n",
    "write( gcd(1362, 1407) ); // Empress Xu (Ming Dynasty) wrote biographies\n",
    "write(\" \");\n",
    "write( gcd(1875, 1907) ); // Qiu Jin, feminist, revolutionary, and writer\n",
    "write(\" \");\n",
    "write( gcd(45,116) ); // Ban Zhao, first known female Chinese historian\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### left pset2-3,pset2-challenge-1 unsolved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
